{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c3f81a01",
   "metadata": {},
   "source": [
    "1) Load Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "860897c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before cleaning: 1000 rows\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import json\n",
    "\n",
    "df = pd.read_csv(\"../data/raw/train.csv\")\n",
    "print(f\"Before cleaning: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53159c2a",
   "metadata": {},
   "source": [
    "2) Remove Duplicate Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d23c6058",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing duplicate conversations: 998 rows\n"
     ]
    }
   ],
   "source": [
    "df = df.drop_duplicates(subset=['conversation'], keep='first')\n",
    "print(f\"After removing duplicate conversations: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "220131e6",
   "metadata": {},
   "source": [
    "3) Remove Very Short Conversations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "93eadd33",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing short conversations: 997 rows\n"
     ]
    }
   ],
   "source": [
    "df['conv_length'] = df['conversation'].str.len()\n",
    "df = df[df['conv_length'] >= 100]\n",
    "print(f\"After removing short conversations: {len(df)} rows\")\n",
    "df = df.drop(columns=['conv_length'])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "abe0c218",
   "metadata": {},
   "source": [
    "4) Remove Invalid QA Rows"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7f348c4b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After removing invalid QA rows: 983 rows\n"
     ]
    }
   ],
   "source": [
    "def is_valid_qa(qa_str):\n",
    "    try:\n",
    "        qa = json.loads(qa_str)\n",
    "        if 'knowledge' not in qa or len(qa['knowledge']) == 0:\n",
    "            return False\n",
    "        for pair in qa['knowledge']:\n",
    "            q = pair.get('customer_summary_question', '').strip()\n",
    "            a = pair.get('agent_summary_solution', '').strip()\n",
    "            if not q or not a:\n",
    "                return False\n",
    "        return True\n",
    "    except:\n",
    "        return False\n",
    "\n",
    "df = df[df['qa'].apply(is_valid_qa)]\n",
    "print(f\"After removing invalid QA rows: {len(df)} rows\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c30afb94",
   "metadata": {},
   "source": [
    "5) Clean Text "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "058beb7a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Cleaned extra whitespace from conversations\n"
     ]
    }
   ],
   "source": [
    "df['conversation'] = df['conversation'].str.strip()\n",
    "df['conversation'] = df['conversation'].str.replace(r'\\s+', ' ', regex=True)\n",
    "print(\"✅ Cleaned extra whitespace from conversations\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79a9aa06",
   "metadata": {},
   "source": [
    "6) Extract QA Pairs into Separate Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "3cb6df12",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total QA pairs extracted: 1881\n",
      "Avg pairs per row: 1.9\n"
     ]
    }
   ],
   "source": [
    "def extract_qa(qa_str):\n",
    "    qa = json.loads(qa_str)\n",
    "    questions = []\n",
    "    answers = []\n",
    "    for pair in qa['knowledge']:\n",
    "        questions.append(pair['customer_summary_question'].strip())\n",
    "        answers.append(pair['agent_summary_solution'].strip())\n",
    "    return questions, answers\n",
    "\n",
    "df['questions'] = df['qa'].apply(lambda x: extract_qa(x)[0])\n",
    "df['answers'] = df['qa'].apply(lambda x: extract_qa(x)[1])\n",
    "\n",
    "print(f\"Total QA pairs extracted: {df['questions'].apply(len).sum()}\")\n",
    "print(f\"Avg pairs per row: {df['questions'].apply(len).mean():.1f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9623330",
   "metadata": {},
   "source": [
    "7) Drop Redundant Columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "c556cc92",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Columns after dropping redundant ones: ['issue_area', 'issue_category', 'issue_sub_category', 'customer_sentiment', 'product_category', 'product_sub_category', 'issue_complexity', 'agent_experience_level', 'conversation', 'qa', 'questions', 'answers']\n"
     ]
    }
   ],
   "source": [
    "df_clean = df.drop(columns=['issue_category_sub_category', 'agent_experience_level_desc'])\n",
    "print(f\"Columns after dropping redundant ones: {df_clean.columns.tolist()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2a7dd59",
   "metadata": {},
   "source": [
    "8) Save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "9ef2f64e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "CLEANING SUMMARY\n",
      "==================================================\n",
      "Original rows: 1000\n",
      "Final rows: 983\n",
      "Removed: 17 rows\n",
      "Columns: 12\n",
      "\n",
      "Final columns: ['issue_area', 'issue_category', 'issue_sub_category', 'customer_sentiment', 'product_category', 'product_sub_category', 'issue_complexity', 'agent_experience_level', 'conversation', 'qa', 'questions', 'answers']\n",
      "\n",
      "✅ Saved to data/processed/cleaned_data.csv\n"
     ]
    }
   ],
   "source": [
    "print(\"=\"*50)\n",
    "print(\"CLEANING SUMMARY\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Original rows: 1000\")\n",
    "print(f\"Final rows: {len(df_clean)}\")\n",
    "print(f\"Removed: {1000 - len(df_clean)} rows\")\n",
    "print(f\"Columns: {len(df_clean.columns)}\")\n",
    "print(f\"\\nFinal columns: {df_clean.columns.tolist()}\")\n",
    "\n",
    "# Save cleaned data\n",
    "df_clean.to_csv(\"../data/processed/cleaned_data.csv\", index=False)\n",
    "print(\"\\n✅ Saved to data/processed/cleaned_data.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f6a312fd",
   "metadata": {},
   "source": [
    "9) Check"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "7d206737",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved file shape: (983, 12)\n",
      "Missing values: 0\n",
      "✅ All good!\n"
     ]
    }
   ],
   "source": [
    "check = pd.read_csv(\"../data/processed/cleaned_data.csv\")\n",
    "print(f\"Saved file shape: {check.shape}\")\n",
    "print(f\"Missing values: {check.isnull().sum().sum()}\")\n",
    "print(\"✅ All good!\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
